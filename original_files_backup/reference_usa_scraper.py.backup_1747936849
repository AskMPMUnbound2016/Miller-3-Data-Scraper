import random
import time
import yaml
import os

class ReferenceUSAScraper:
    def __init__(self, config_file):
        # Load configuration
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
        
        # Extract config values
        self.download_dir = self.config.get('download_dir', os.path.join(os.getcwd(), "downloads"))
        self.auth_url = self.config.get('auth_url')
        self.library_credentials = self.config.get('library_credentials', {})
        self.search_parameters = self.config.get('search_parameters', {})
        self.pages_per_batch = self.config.get('pages_per_batch', 10)
        self.pages_to_download = self.config.get('pages_to_download', 'all')
        self.state_file = self.config.get('state_file', 'reference_usa_state.json')
        
        # Import needed modules
        from state_manager import StateManager
        from browser_manager import BrowserManager
        from login_manager import LoginManager
        from search_manager import SearchManager
        from download_manager import DownloadManager
        
        # Create components
        self.state_manager = StateManager(self.state_file)
        self.browser_manager = BrowserManager(self.download_dir)
        self.login_manager = LoginManager(self.browser_manager, self.auth_url, self.library_credentials)
        self.search_manager = SearchManager(self.browser_manager, self.state_manager, self.search_parameters)
        self.download_manager = DownloadManager(self.browser_manager, self.state_manager, self.search_parameters)
    
    def run(self, start_batch=None, end_batch=None):
        """Run the scraper for specified batch range"""
        try:
            # Determine batch range
            if start_batch is None:
                start_batch = self.state_manager.state["last_batch"] + 1
            
            if end_batch is None:
                if self.pages_to_download == 'all':
                    if self.state_manager.state["total_batches"] > 0:
                        end_batch = self.state_manager.state["total_batches"]
                    else:
                        end_batch = 100  # Default if total unknown
                else:
                    end_batch = self.pages_to_download
            
            print(f"\n=== ReferenceUSA Scraper ===")
            print(f"Starting batch: {start_batch}")
            print(f"Ending batch: {end_batch}")
            
            # Login to ReferenceUSA
            if not self.login_manager.login():
                print("Cannot proceed without successful login")
                return
            
            # If we have a stored results URL and resuming, go there directly
            if self.state_manager.state["results_url"] and start_batch > 1:
                print(f"Resuming from previous session...")
                self.browser_manager.navigate(self.state_manager.state["results_url"])
            else:
                # Otherwise navigate to search page and set criteria
                if not self.search_manager.navigate_to_search():
                    print("Failed to navigate to search page")
                    return
                    
                if not self.search_manager.apply_search_criteria():
                    print("Failed to apply search criteria")
                    return
            
            # Process each batch
            for batch in range(start_batch, end_batch + 1):
                # Skip already completed batches
                if self.state_manager.is_batch_completed(batch):
                    print(f"Batch {batch} already completed, skipping...")
                    continue
                
                # Download current batch
                if not self.download_manager.download_batch(batch):
                    print(f"Failed on batch {batch}, stopping")
                    break
                    
                # Random delay between batches to avoid triggering security measures
                if batch < end_batch:
                    delay = random.uniform(8, 12)
                    print(f"Waiting {delay:.1f} seconds before next batch...")
                    time.sleep(delay)
            
            print(f"\n=== Scraping complete ===")
            print(f"Last batch processed: {self.state_manager.state['last_batch']}")
            print(f"Total files downloaded: {len(self.state_manager.state['downloaded_files'])}")
            
        except Exception as e:
            print(f"Unexpected error: {str(e)}")
        finally:
            self.browser_manager.close()
